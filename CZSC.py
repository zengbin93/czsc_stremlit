import os
import streamlit as st

st.set_page_config(page_title="çŸ¥è¯†é—®ç­”", page_icon="ğŸ¤–", layout="wide")


@st.cache_resource
def initialize_model(model_name='qwen-max-1201', api_key=None, api_base=None):
    from langchain.vectorstores import DeepLake
    from langchain.chat_models import ChatOpenAI
    from langchain.chains import RetrievalQA
    from langchain.embeddings.openai import OpenAIEmbeddings

    os.environ["OPENAI_API_KEY"] = st.secrets['OPENAI_API_KEY'] if api_key is None else api_key
    os.environ['OPENAI_API_BASE'] = st.secrets['OPENAI_API_BASE'] if api_base is None else api_base
    os.environ['ACTIVELOOP_TOKEN'] = st.secrets['ACTIVELOOP_TOKEN']

    embeddings = OpenAIEmbeddings()
    db = DeepLake(dataset_path='hub://zengbin93/czsc', read_only=True, embedding_function=embeddings)

    retriever = db.as_retriever()
    retriever.search_kwargs['distance_metric'] = 'cos'
    retriever.search_kwargs['k'] = 20
    model = ChatOpenAI(model=model_name)
    qa = RetrievalQA.from_llm(model, retriever=retriever)
    return qa


def show_kbqa():
    """

    å‚è€ƒèµ„æ–™ï¼š

    1. https://github.com/chatchat-space/Langchain-Chatchat
    2. https://docs.streamlit.io/knowledge-base/tutorials/build-conversational-apps

    """
    allow_gpt4_users = st.secrets['allow_gpt4_users']

    st.subheader("CZSCä»£ç åº“QA", divider="rainbow")
    c1, c2, c3, c4, c5 = st.columns([3, 3, 3, 1, 1])
    api_help = "ä»»ä½•æ”¯æŒ OpenAI API çš„æ¨¡å‹éƒ½å¯ä»¥ä½¿ç”¨ã€‚API_KEY å’Œ API_BASE å¿…é¡»åŒæ—¶æä¾›ï¼Œå¦åˆ™ä½¿ç”¨é»˜è®¤å€¼ã€‚"
    api_key = c1.text_input(label="è¯·è¾“å…¥API_KEY", value="ä½¿ç”¨é»˜è®¤å€¼", help=api_help)
    api_base = c2.text_input(label="è¯·è¾“å…¥API_BASE", value="ä½¿ç”¨é»˜è®¤å€¼", help=api_help)
    model_name = c3.selectbox(label="è¯·é€‰æ‹©æ¨¡å‹", options=['Baichuan2', 'qwen-max-1201', 'gpt-4'], index=0)
    if c4.button("æ¸…ç©ºå†å²æ¶ˆæ¯"):
        st.session_state.messages = []
    if c5.button("å¾®ä¿¡æèµ æ”¯æŒï¼Œæ¥GPT4"):
        st.success("æ„Ÿè°¢æ”¯æŒï¼Œè¯·åŠ å¾®ä¿¡ï¼šzengbin93ï¼Œå¤‡æ³¨ï¼šæèµ ")
    st.divider()
    if model_name == 'gpt-4' and st.experimental_user.email not in allow_gpt4_users:
        st.warning(f"æŠ±æ­‰ï¼Œæ‚¨ï¼ˆst.experimental_user.emailï¼‰æ²¡æœ‰æƒé™ä½¿ç”¨ GPT-4 æ¨¡å‹ã€‚GPT-4 æ¨¡å‹è°ƒç”¨æˆæœ¬è¾ƒé«˜ï¼Œéœ€è¦æèµ æ”¯æŒã€‚è¯·åŠ å¾®ä¿¡ï¼šzengbin93ï¼Œå¤‡æ³¨ï¼šæèµ ")
        st.stop()

    api_key = None if api_key == "ä½¿ç”¨é»˜è®¤å€¼" else api_key
    api_base = None if api_base == "ä½¿ç”¨é»˜è®¤å€¼" else api_base
    qa = initialize_model(model_name=model_name, api_key=api_key, api_base=api_base)

    # Initialize chat history
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # Display chat messages from history on app rerun
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # Accept user input
    if prompt := st.chat_input("What is up?"):
        # Add user message to chat history
        st.session_state.messages.append({"role": "user", "content": prompt})
        # Display user message in chat message container
        with st.chat_message("user"):
            st.markdown(prompt)
        # Display assistant response in chat message container
        with st.chat_message("assistant"):
            response = qa.run(prompt)
            st.markdown(response)
            st.session_state.messages.append({"role": "assistant", "content": response})


if __name__ == '__main__':
    show_kbqa()
